{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpx<0.29,>=0.27 (from ollama)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting anyio (from httpx<0.29,>=0.27->ollama)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.29,>=0.27->ollama)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.29,>=0.27->ollama)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<0.29,>=0.27->ollama)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.2/2.6 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.7/2.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 166.4/166.4 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.8/102.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 431.7/431.7 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.8/2.0 MB 17.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.8 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.4/128.4 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.0/96.0 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, sniffio, Pillow, idna, h11, charset-normalizer, certifi, annotated-types, requests, pydantic-core, httpcore, anyio, pydantic, httpx, ollama\n",
      "Successfully installed Pillow-11.1.0 annotated-types-0.7.0 anyio-4.8.0 certifi-2025.1.31 charset-normalizer-3.4.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 ollama-0.4.7 pydantic-2.10.6 pydantic-core-2.27.2 requests-2.32.3 sniffio-1.3.1 typing-extensions-4.12.2 urllib3-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 설치\n",
    "!pip install requests Pillow ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from requests) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (11.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\success\\localllm\\ollamatest\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# requests 설치\n",
    "!pip install requests\n",
    "\n",
    "# json 모듈은 Python 내장 모듈이므로 별도 설치 필요 없음\n",
    "\n",
    "# Pillow 설치 (PIL은 Pillow로 대체됨)\n",
    "!pip install Pillow\n",
    "\n",
    "# base64 및 io 모듈은 Python 내장 모듈이므로 별도 설치 필요 없음\n",
    "\n",
    "# ollama 설치\n",
    "!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# LLaVA 모델을 사용하여 질문에 대한 답변 요청\n",
    "def ask_question(question):\n",
    "    response = ollama.chat(\n",
    "        model=\"llava:7b\",\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': question\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 제가 언급하는 것은 \"컴퓨터 프로그래밍\"이며, 이를 실행하기 위해서는 \"코딩\"이라는 과정을 거칩니다.\n",
      "\n",
      "\"코딩\"은 컴퓨터에게 무엇을 해야 할지에 대한 명령을 알려주는 것입니다. 이를 통해 컴퓨터는 원하는 작업을 수행할 수 있습니다.\n",
      "\n",
      "예를 들어, 웹 페이지를 만들기 위해서는 HTML, CSS, JavaScript와 같은 언어로 코드를 작성한 후, 컴퓨터에게 이 코드를 실행시키면 됩니다. 이때 \"코딩\"이라는 과정을 거칩니다.\n",
      "\n",
      "따라서 \"코딩\"은 컴퓨터 프로그래밍의 중요한 단계 중 하나입니다. \n"
     ]
    }
   ],
   "source": [
    "result = ask_question(\"너는 누군인지 한글로 설명해줘!\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM은 언어 모델(Language Model)의 약자입니다. 이는 인공지능의 중요한 분야 중 하나인 NLP(Natural Language Processing)에서 사용됩니다.\n",
      "\n",
      "LLM은 텍스트 데이터를 처리할 수 있도록 학습되어 있으며, 입력된 텍스트에서 단어를 추측하거나 문장의 의미를 파악할 수 있습니다. LLM은 대규모의 데이터베이스(e.g., 인터넷)에서 학습되었기 때문에, 입력된 텍스트에서 보이는 패턴을 학습하여 예측할 수 있습니다.\n",
      "\n",
      "LLM은 대표적으로 BERT, GPT-3 등의 모델로 사용됩니다. LLM은 인공지능의 한계를 점명하는데, LLM은 문법적 에러를 발견할 수 없고, 이미 학습된 정보만을 활용합니다. 또한, LLM은 인터넷의 데이터 공급이 멈축되거나 새로운 언어가 발생할 때는 LLM의 능력성이 감소할 수 있습니다.\n",
      "\n",
      "따라서, LLM은 인공지능에서 중요한 역할을 하지만, 인터넷의 데이터 공급이나 언어의 변화가 발생할 때는 LLM의 기능성이 제한됩니다. \n"
     ]
    }
   ],
   "source": [
    "result = ask_question(\"LLM 모델에 대해서 한글로 설명해줘!\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image shows a robotic figure with humanoid characteristics. It has a white body, blue accents, and appears to have a friendly demeanor. The robot is designed with a face that has eyes, a mouth with teeth, and it seems to have hands that are capable of interacting with the environment. Additionally, there's what looks like a camera or sensor on the head, which might be used for navigation or interaction.\n",
      "\n",
      "The robot is positioned in a standing posture, as if ready to move or perform an action. Its legs are apart, and it has arms that can possibly hold objects or manipulate tasks. The overall design suggests that this robot could be used for various applications such as customer service, education, or even in the home as a helper or companion robot. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# 테스트할 이미지 파일 경로\n",
    "image_path = \"./robot.jpg\"  # 이미지 파일 경로를 입력하세요\n",
    "\n",
    "# 사용자 질문\n",
    "question = \"이 이미지에 대해 설명해주세요.\"\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"이미지 파일을 Base64 문자열로 인코딩합니다.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return encoded_string\n",
    "\n",
    "try:\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    response = ollama.chat(\n",
    "        model=\"llava:7b\",\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': question,\n",
    "                'images': [base64_image]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(response['message']['content'])\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"예상치 못한 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama 응답:\n",
      " \"이 사진에는 두 개의 로봇이 있습니다. 로봇은 크기와 색상으로 나눠져 있습니다. 더 큰 로봇은 오른쪽, 더 작은 로봇은 왼쪽입니다. 이들은 모두 자동차를 기본으로 가지고 있는 것을 알 수 있습니다. 그러나 큰 로봇은 더 작은 로봇의 오른쪽에 있습니다. 큰 로봇은 자동차를 들고 있으며, 이는 왼쪽에서 움을 내놓고 있어서 자신의 크기와 위치를 표시하며, 더 작은 로봇은 큰 로봇의 오른쪽에서 왼쪽으로 자동차를 들고 있습니다.\n",
      "\n",
      "이들은 모두 실제로 있는 것을 알 수 있습니다. 그러나 두 개의 로봇은 실제로 존재하지 않으므로, 이 사진은 얼굿이나 디자인의 예상적인 형태입니다.\" \n"
     ]
    }
   ],
   "source": [
    "#방법2\n",
    "# Ollama API 엔드포인트 (기본값)\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "# 테스트할 이미지 파일 경로\n",
    "image_path = \"./robot.jpg \"   # 이미지 파일 경로를 입력하세요\n",
    "\n",
    "# 모델 이름\n",
    "model_name = \"llava:7b\"\n",
    "\n",
    "# 사용자 프롬프트\n",
    "prompt = \"이 이미지에 대해 한국어로 설명하세요\"\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"이미지 파일을 Base64 문자열로 인코딩합니다.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return encoded_string\n",
    "\n",
    "def get_ollama_response(model, prompt, images=None):\n",
    "    \"\"\"Ollama API에 요청을 보내고 응답을 받습니다.\"\"\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                \"images\": images if images else []\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False  # 스트리밍 응답을 받지 않도록 설정\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API_URL, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['message']['content']\n",
    "    else:\n",
    "        print(f\"오류 발생: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 이미지 Base64 인코딩\n",
    "        base64_image = encode_image_to_base64(image_path)\n",
    "\n",
    "        # Ollama API에 요청\n",
    "        response = get_ollama_response(model_name, prompt, images=[base64_image])\n",
    "\n",
    "        if response:\n",
    "            print(\"Ollama 응답:\")\n",
    "            print(response)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"오류: Ollama API 서버에 연결할 수 없습니다. 서버가 실행 중인지 확인하세요 ({OLLAMA_API_URL}).\")\n",
    "    except Exception as e:\n",
    "        print(f\"예상치 못한 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollamaTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
